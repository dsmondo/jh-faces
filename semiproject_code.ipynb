{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMwZJMMZWBHiW/a7UUpFKfv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dsmondo/jh-faces/blob/main/semiproject_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANOVA"
      ],
      "metadata": {
        "id": "DKl8XdIXgVpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test for differences in the mean of the variable (analysis of variance)\n",
        "# One-way ANOVA (Analysis of Variance)\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd, MultiComparison\n",
        "import pingouin as pg\n",
        "\n",
        "# num_cols - Charger_type\n",
        "def levene_anova(col):\n",
        "\n",
        "    target_list = [0, 1, 2, 3]\n",
        "\n",
        "    zero = df.loc[df['Charger_type'] == 0,col]\n",
        "    slow = df.loc[df['Charger_type'] == 1,col]\n",
        "    fast = df.loc[df['Charger_type'] == 2,col]\n",
        "    both = df.loc[df['Charger_type'] == 3,col]\n",
        "\n",
        "    levene = stats.levene(zero, slow, fast, both)\n",
        "\n",
        "    # levene-test\n",
        "    if levene[1] < 0.05:\n",
        "        print(\"MESSAGE: At least one of the variances among the groups is different.\")\n",
        "        # Welch's ANOVA since H0 is rejected\n",
        "        welch = pg.welch_anova(dv=col, between='Charger_type', data=df)\n",
        "\n",
        "        if welch['p-unc'].item() < 0.05:\n",
        "            print(f'MESSAGE: Reject the null hypothesis that the {col} are equal between the 7 groups')\n",
        "\n",
        "            # post-hoc test\n",
        "            mc = MultiComparison(data=df[col], groups=df['Charger_type'])\n",
        "            tukeyhsd = mc.tukeyhsd(alpha=0.05)\n",
        "            fig = tukeyhsd.plot_simultaneous()\n",
        "\n",
        "            print(tukeyhsd.summary())\n",
        "\n",
        "        else:\n",
        "            print(f'MESSAGE: Accept the null hypothesis that the {col} are equal between the 7 groups')\n",
        "\n",
        "    else:\n",
        "        print(\"MESSAGE: All groups have equal variances.\")\n",
        "        # ANOVA since H0 is accepted\n",
        "        anova = stats.f_oneway(zero, slow, fast, both)\n",
        "\n",
        "        if anova[1] < 0.05:\n",
        "            print(f'MESSAGE: Reject the null hypothesis that the {col} are equal between the 7 groups')\n",
        "            mc = MultiComparison(data=df[col], groups=df['Charger_type'])\n",
        "            tukeyhsd = mc.tukeyhsd(alpha=0.05)\n",
        "            fig = tukeyhsd.plot_simultaneous()\n",
        "\n",
        "            print(tukeyhsd.summary())\n",
        "\n",
        "        else:\n",
        "             print(f'MESSAGE: Accept the null hypothesis that the {col} are equal between the 7 groups')"
      ],
      "metadata": {
        "id": "Cp7VZ27tgTFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Correlation Heatmap"
      ],
      "metadata": {
        "id": "nX1bb_0YiYH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "font_path = \"/MultiCampus/Malgun.ttf\"\n",
        "font_name = fm.FontProperties(fname=font_path).get_name()\n",
        "rc('font', family=font_name)\n",
        "\n",
        "corr = final_df[['Gas_station_count', 'Charger_ACC', 'Performance_facility_ACC', 'Land_Price', 'Library_ACC',\n",
        "                'Hospital_ACC', 'Healthcare_Facility_ACC', 'Community_Park_ACC', 'Fire_Station_ACC', 'Population',\n",
        "                'Theme_Park_ACC', 'Parking_lot_ACC', 'Sports_Facility_ACC', 'Elementary_School_ACC', 'Farmland',\n",
        "                'Stream', 'Altitude', 'Charger_type']]\n",
        "\n",
        "plt.figure(figsize=(15, 8))\n",
        "sns.heatmap(corr.corr(), annot=True, cmap='viridis', vmax=1, vmin=-1)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0r5ks2YCiacZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generation of Train dataset"
      ],
      "metadata": {
        "id": "ZY4XMq9Rby5x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2r74gRXWgSvm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcfOBSq3YjzS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# Read the CSV file\n",
        "df = pd.read_csv('intersection_ratio.csv', encoding='cp949')\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df.drop(['fid', 'emd_cd', 'emd_nm_k', 'no_charging', 'centerpoint', 'centerpoint_2', 'area'], axis=1, inplace=True)\n",
        "\n",
        "# Columns to multiply\n",
        "columns_to_multiply = ['Charger_ACC', 'Gas_station_count', 'Performance_facility_ACC', 'Land_Price', 'Library_ACC',\n",
        "                       'Hospital_ACC', 'Healthcare_Facility_ACC', 'Community_Park_ACC', 'Fire_Station_ACC', 'Theme_Park_ACC',\n",
        "                       'Parking_lot_ACC', 'Sports_Facility_ACC', 'Elementary_School_ACC', 'Population']\n",
        "\n",
        "# Values multiplied by area ratio\n",
        "for column in columns_to_multiply:\n",
        "    df[column] = df[column] * df['area_ratio']\n",
        "\n",
        "# Round and convert 'Population' and 'Gas_station_count' columns to integers\n",
        "df['Population'] = df['Population'].round().astype(int)\n",
        "df['Gas_station_count'] = df['Gas_station_count'].round().astype(int)\n",
        "\n",
        "# Create a new DataFrame with selected columns\n",
        "columns_to_multiply2 = ['rand_point_id', 'Charger_ACC', 'Gas_station_count', 'Performance_facility_ACC', 'Land_Price', 'Library_ACC',\n",
        "                        'Hospital_ACC', 'Healthcare_Facility_ACC', 'Community_Park_ACC', 'Fire_Station_ACC', 'Theme_Park_ACC',\n",
        "                        'Parking_lot_ACC', 'Sports_Facility_ACC', 'Elementary_School_ACC', 'Population']\n",
        "df1 = df[columns_to_multiply2]\n",
        "\n",
        "# Group by 'rand_point_id' and sum the values\n",
        "df1_sum = df1.groupby('rand_point_id').sum()\n",
        "\n",
        "# Group by 'rand_point_id' and check if 'farmland' is included\n",
        "df2 = df.groupby('rand_point_id')['farmland'].apply(lambda x: int(1 in x.values)).reset_index(name='farmland_YN')\n",
        "\n",
        "# Group by 'rand_point_id' and check if 'stream' is included\n",
        "df3 = df.groupby('rand_point_id')['stream'].apply(lambda x: int(1 in x.values)).reset_index(name='stream_YN')\n",
        "\n",
        "# Merge df1_sum and df2 on 'rand_point_id'\n",
        "merged_df = pd.merge(df1_sum, df2, on='rand_point_id', how='inner')\n",
        "\n",
        "# Merge merged_df and df3 on 'rand_point_id'\n",
        "final_merged_df = pd.merge(merged_df, df3, on='rand_point_id', how='inner')\n",
        "\n",
        "# Print the final merged DataFrame\n",
        "final_merged_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning"
      ],
      "metadata": {
        "id": "X8GBNqy5eKPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Load data\n",
        "train = pd.read_csv(\"/content/drive/MyDrive/naju/train_data.csv\")\n",
        "test = pd.read_csv(\"/content/drive/MyDrive/naju/test_data.csv\")\n",
        "\n",
        "# Align column names and select necessary columns\n",
        "# train.rename(columns={'급/완속여부_new': '급/완속여부', '평균고도': '고도'}, inplace=True)\n",
        "# test.rename(columns={'평균고도': '고도'}, inplace=True)\n",
        "\n",
        "y_train = train['Charger_type']\n",
        "y_test = test['Charger_type']\n",
        "X_train = train.drop(columns=['Charger_type', 'Unnamed: 0', 'rand_point_id', 'Charger_ACC', 'Gas_station_count'])\n",
        "X_test = test.drop(columns=['Charger_type', 'Charger_cnt', 'Unnamed: 0', 'fid', 'gid', 'emd_cd', 'emd_nm_k', 'centerpoint', 'geometry'])\n",
        "\n",
        "# Align column order between train and test datasets\n",
        "X_test = X_test[X_train.columns]\n",
        "\n",
        "# Apply RobustScaler\n",
        "scaler = RobustScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Apply SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "# Initialize models\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "lgb_model = lgb.LGBMClassifier(random_state=42)\n",
        "xgb_model = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n",
        "\n",
        "# Train each model\n",
        "rf_model.fit(X_train_smote, y_train_smote)\n",
        "lgb_model.fit(X_train_smote, y_train_smote)\n",
        "xgb_model.fit(X_train_smote, y_train_smote)\n",
        "\n",
        "# Predictions for each model\n",
        "y_pred_rf = rf_model.predict(X_test_scaled)\n",
        "y_pred_lgb = lgb_model.predict(X_test_scaled)\n",
        "y_pred_xgb = xgb_model.predict(X_test_scaled)\n",
        "\n",
        "# Model evaluation\n",
        "print(\"RandomForest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(confusion_matrix(y_test, y_pred_rf))\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "\n",
        "print(\"LightGBM Accuracy:\", accuracy_score(y_test, y_pred_lgb))\n",
        "print(confusion_matrix(y_test, y_pred_lgb))\n",
        "print(classification_report(y_test, y_pred_lgb))\n",
        "\n",
        "print(\"XGBoost Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
        "print(confusion_matrix(y_test, y_pred_xgb))\n",
        "print(classification_report(y_test, y_pred_xgb))\n",
        "\n",
        "# Voting Classifier\n",
        "estimators = [('rf', rf_model), ('lgb', lgb_model), ('xgb', xgb_model)]\n",
        "voting_clf = VotingClassifier(estimators=estimators, voting='soft')\n",
        "voting_clf.fit(X_train_smote, y_train_smote)  # Retrain using SMOTE-applied data\n",
        "\n",
        "# Predictions and evaluation for Voting Classifier\n",
        "y_pred_voting = voting_clf.predict(X_test_scaled)\n",
        "print(\"Voting Classifier Accuracy (SMOTE):\", accuracy_score(y_test, y_pred_voting))\n",
        "print(confusion_matrix(y_test, y_pred_voting))\n",
        "print(classification_report(y_test, y_pred_voting))\n",
        "\n",
        "# Add predictions of each model to the test DataFrame\n",
        "test['y_pred_rf'] = rf_model.predict(X_test_scaled)\n",
        "test['y_pred_lgb'] = lgb_model.predict(X_test_scaled)\n",
        "test['y_pred_xgb'] = xgb_model.predict(X_test_scaled)\n",
        "test['y_pred_voting'] = voting_clf.predict(X_test_scaled)\n",
        "\n",
        "# Indices where actual is '0' but model predicts '1', '2', or '3'\n",
        "fp_indices_rf = test[(test['Charger_type'] == 0) & (test['y_pred_rf'].isin([1, 2, 3]))].index.tolist()\n",
        "fp_indices_lgb = test[(test['Charger_type'] == 0) & (test['y_pred_lgb'].isin([1,2,3]))].index.tolist()\n",
        "fp_indices_xgb = test[(test['Charger_type'] == 0) & (test['y_pred"
      ],
      "metadata": {
        "id": "-8MI_C_IbsY7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}